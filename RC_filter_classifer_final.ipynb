{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time as time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(\"TensorFlow version:\",tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir =\"/tmp/RC_filter/data/\"\n",
    "model_dir =\"/tmp/RC_filter/\"\n",
    "summaries_dir = \"/tmp/RC_filter/logs/1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract data from CSV\n",
    "df1=pd.read_csv(data_dir+\"RC_filter_classify.csv\")\n",
    "col1 = df1[['R1','C1','R2','C2']]\n",
    "col2 = df1[['LP','HP','BP','NA']]\n",
    "col3 = df1[['fL','fH']]\n",
    "#Convert to Numpy array\n",
    "InputX1 = col1.as_matrix()\n",
    "InputY1 = col2.as_matrix()\n",
    "plotX = col3.as_matrix()\n",
    "InputX1.astype(float, copy=False);\n",
    "InputY1.astype(float, copy=False);\n",
    "plotX.astype(float, copy=False);\n",
    "#print(\"Input:\",InputX1)\n",
    "#print(\"Output:\",InputY1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAFkCAYAAACAUFlOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyvAhSZIKZfiQJEmFMnxIkqRC/X/q6bdYxTzxeQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24e9236ae80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(plotX[1:26,0:1],plotX[1:26,1:2], 'ro')  #Low Pass filter\n",
    "plt.plot(plotX[59:74,0:1],plotX[59:74,1:2], 'bo') #Band Pass filter\n",
    "plt.axis([-1e1, 3e3, -1e1, 5e3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mininum values: [ 0.  0.  0.  0.]\n",
      "Maximum values: [  2.30000000e+04   3.59000000e-07   3.20000000e+04   5.15000000e-07]\n"
     ]
    }
   ],
   "source": [
    "#Data Preprocessing\n",
    "X1_min = np.amin(InputX1,0)     #Find minimum and maximum\n",
    "X1_max = np.amax(InputX1,0)   \n",
    "print(\"Mininum values:\",X1_min)  \n",
    "print(\"Maximum values:\",X1_max)\n",
    "Y1_min = np.amin(InputY1)     \n",
    "Y1_max = np.amax(InputY1) \n",
    "InputX1_norm = (InputX1-X1_min)/(X1_max-X1_min)  #Min-max Normalization on input data\n",
    "InputY1_norm = InputY1  #No normalization on output data\n",
    "#InputY1_norm = (InputY1-Y1_min)/(Y1_max-Y1_min)\n",
    "\n",
    "#Reshape input data [sample_size,input_features]\n",
    "Xfeatures = 4 #Number of input features\n",
    "Yfeatures = 4 #Number of output features\n",
    "samples = 145 # Number of samples\n",
    "\n",
    "InputX1_reshape = np.resize(InputX1_norm,(samples,Xfeatures))\n",
    "InputY1_reshape = np.resize(InputY1_norm,(samples,Yfeatures))\n",
    "#print(\"X1 normalized:\",InputX1_reshape)\n",
    "#print(\"Y1 normalized:\",InputY1_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Training data\n",
    "batch_size = 130\n",
    "InputX1train = InputX1_reshape[0:batch_size,:]\n",
    "InputY1train = InputY1_reshape[0:batch_size,:]\n",
    "#Validation data\n",
    "v_size = samples-batch_size\n",
    "InputX1v = InputX1_reshape[batch_size:batch_size+v_size,:]\n",
    "InputY1v = InputY1_reshape[batch_size:batch_size+v_size,:]\n",
    "#print(InputX1v)\n",
    "#print(InputY1v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Network hyper parametres\n",
    "learning_rate0 = 0.0001\n",
    "training_epochs = 40000\n",
    "display_epoch = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reset everything to rerun in jupyter\n",
    "tf.reset_default_graph()\n",
    "with tf.device('/cpu:0'):\n",
    "    #Input\n",
    "    X = tf.placeholder(tf.float32,shape=(None,Xfeatures),name=\"X\")#[batch size, input_features]\n",
    "    #Output\n",
    "    Y = tf.placeholder(tf.float32,shape=(None,Yfeatures),name=\"Labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Neurons\n",
    "L1 = 4 #Number of neurons in 1st layer\n",
    "#Layer1 weights\n",
    "with tf.device('/cpu:0'):\n",
    "    with tf.name_scope('Layer_1'):\n",
    "        W_fc1 = tf.Variable(tf.random_uniform([Xfeatures,L1]),name=\"W\") # [input_features,Number of neurons]) \n",
    "        b_fc1 = tf.Variable(tf.random_uniform([L1]),name=\"bias\")\n",
    "        matmul_fc1=tf.matmul(X, W_fc1) + b_fc1  #Weights * Inputs\n",
    "        tf.summary.histogram(\"Layer1_Weights\",W_fc1)\n",
    "        tf.summary.histogram(\"Layer1_biases\",b_fc1)\n",
    "    with tf.name_scope('ReLU'):\n",
    "        h_fc1 = tf.nn.relu(matmul_fc1)   #ReLU activation\n",
    "        #h_fc1=tf.sigmoid(matmul_fc1)     #Sigmoid activation\n",
    "        \n",
    "#Output layer\n",
    "    with tf.name_scope('Output_Layer') as scope:\n",
    "        W_fO= tf.Variable(tf.random_uniform([L1,Yfeatures]),name=\"W\") #  [Number of neurons in preceding layer,output_features]) \n",
    "        b_fO = tf.Variable(tf.random_uniform([Yfeatures]),name=\"bias\")\n",
    "        matmul_fco= tf.matmul(h_fc1, W_fO) + b_fO\n",
    "        output_layer = matmul_fco  #linear activation\n",
    "        tf.summary.histogram(\"Output_Layer_Weights\",W_fO)\n",
    "        tf.summary.histogram(\"Output_Layer_biases\",b_fO)\n",
    "    with tf.name_scope('Softmax') as scope:\n",
    "        output_layer_prob = tf.nn.softmax(output_layer)  #Applying softmax activation to find probabilities for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    #Loss/cost function\n",
    "    with tf.name_scope('Cross_Entropy'):\n",
    "        soft_cross_entropy = tf.losses.softmax_cross_entropy(Y,output_layer)\n",
    "        tf.summary.scalar('softmax_cross_entropy', soft_cross_entropy)\n",
    "\n",
    "    #Decreasing learning rate\n",
    "    with tf.name_scope('Learning_rate'):\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        starter_learning_rate = learning_rate0\n",
    "        learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,10000, 0.96, staircase=True)\n",
    "#Calculate accuracy\n",
    "    with tf.name_scope('Accuracy'):\n",
    "        #accuracy,update_accuracy = tf.metrics.accuracy(class_labels,class_pred)\n",
    "        class_pred = tf.arg_max(output_layer_prob,dimension=1)  #Find predicted class label (class with highest probability)\n",
    "        class_labels =tf.arg_max(Y,dimension=1)               #Find original class label\n",
    "        correct_prediction = tf.equal(class_pred,class_labels)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        tf.summary.scalar('Prediction_Accuracy', accuracy)\n",
    "        \n",
    "with tf.device('/cpu:0'):\n",
    "    #Training step\n",
    "    with tf.name_scope('Optimizer'):\n",
    "        #train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(soft_cross_entropy,global_step=global_step)\n",
    "        #train_step = tf.train.AdamOptimizer(learning_rate).minimize(soft_cross_entropy,global_step=global_step)\n",
    "        train_step = tf.train.AdagradOptimizer(learning_rate).minimize(soft_cross_entropy,global_step=global_step)\n",
    "    \n",
    "\n",
    "# Merge all the summaries\n",
    "merged = tf.summary.merge_all()\n",
    "    \n",
    "#Operation to save variables\n",
    "saver = tf.train.Saver()\n",
    "#Path for tensorboard\n",
    "#tensorboard --logdir=/tmp/RC_Filter/logs/1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Training loss: [1.3159648]\n",
      "Iteration: 0\n",
      "Training loss: [1.3159524]\n",
      "Training accuracy: [0.55384618]\n",
      "Validation loss: [1.343392]\n",
      "Learning rate: [9.9999997e-05]\n",
      "Iteration: 5000\n",
      "Training loss: [1.3050561]\n",
      "Training accuracy: [0.60000002]\n",
      "Validation loss: [1.3367528]\n",
      "Learning rate: [9.9999997e-05]\n",
      "Iteration: 10000\n",
      "Training loss: [1.3000376]\n",
      "Training accuracy: [0.60000002]\n",
      "Validation loss: [1.3348101]\n",
      "Learning rate: [9.5999996e-05]\n",
      "Iteration: 15000\n",
      "Training loss: [1.2963524]\n",
      "Training accuracy: [0.60000002]\n",
      "Validation loss: [1.3338215]\n",
      "Learning rate: [9.5999996e-05]\n",
      "Iteration: 20000\n",
      "Training loss: [1.2932423]\n",
      "Training accuracy: [0.60000002]\n",
      "Validation loss: [1.3332531]\n",
      "Learning rate: [9.2159993e-05]\n",
      "Iteration: 25000\n",
      "Training loss: [1.2906071]\n",
      "Training accuracy: [0.60000002]\n",
      "Validation loss: [1.3329132]\n",
      "Learning rate: [9.2159993e-05]\n",
      "Iteration: 30000\n",
      "Training loss: [1.2882202]\n",
      "Training accuracy: [0.60000002]\n",
      "Validation loss: [1.3327273]\n",
      "Learning rate: [8.8473593e-05]\n",
      "Iteration: 35000\n",
      "Training loss: [1.28611]\n",
      "Training accuracy: [0.60000002]\n",
      "Validation loss: [1.3325806]\n",
      "Learning rate: [8.8473593e-05]\n",
      "Model saved in file: /tmp/RC_filter/RC_classifier.ckpt\n",
      "Final training loss: [1.2841278]\n",
      "Final Training accuracy: [0.60000002]\n",
      "Final validation loss: [1.3325483]\n",
      "Time taken (seconds): 56.097673416137695  seconds\n"
     ]
    }
   ],
   "source": [
    "#Initialization and session\n",
    "init = tf.global_variables_initializer()\n",
    "init_local = tf.local_variables_initializer()\n",
    "tstart = time.time()\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True,log_device_placement=True)) as sess:\n",
    "    train_writer = tf.summary.FileWriter(summaries_dir,sess.graph)  #For writing summaries\n",
    "    sess.run([init,init_local])  #Initializes all variables\n",
    "    print(\"Initial Training loss:\",sess.run([soft_cross_entropy],feed_dict={X:InputX1train,Y:InputY1train}))\n",
    "    for i in range(training_epochs):\n",
    "        summary,_ = sess.run([merged,train_step],feed_dict={X:InputX1train,Y:InputY1train})\n",
    "        train_writer.add_summary(summary, i)\n",
    "        \n",
    "        if i%display_epoch ==0:\n",
    "            print(\"Iteration:\",i)\n",
    "            print(\"Training loss:\",sess.run([soft_cross_entropy],feed_dict={X:InputX1train,Y:InputY1train}))\n",
    "            print(\"Training accuracy:\",sess.run([accuracy],feed_dict={X:InputX1train,Y:InputY1train}))\n",
    "            print(\"Validation loss:\",sess.run([soft_cross_entropy],feed_dict={X:InputX1v,Y:InputY1v}))\n",
    "            print(\"Learning rate:\",sess.run([learning_rate]))   \n",
    "    #Close summary writer\n",
    "    train_writer.close()\n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(sess, model_dir+\"RC_classifier.ckpt\")\n",
    "    #/tmp/RC_filter/RC_classifier.ckpt\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    print(\"Final training loss:\",sess.run([soft_cross_entropy],feed_dict={X:InputX1train,Y:InputY1train}))\n",
    "    print(\"Final Training accuracy:\",sess.run([accuracy],feed_dict={X:InputX1train,Y:InputY1train}))\n",
    "    print(\"Final validation loss:\",sess.run([soft_cross_entropy],feed_dict={X:InputX1v,Y:InputY1v}))\n",
    "    #print(\"Labels:\",sess.run([class_labels],feed_dict={Y:InputY1train}))\n",
    "    #print(\"Prediction:\",sess.run([class_pred],feed_dict={X:InputX1train}))\n",
    "print(\"Time taken (seconds):\", time.time()-tstart,\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "Training loss: [1.2841278]\n",
      "Layer1_Weights: [array([[ 0.11403678,  0.38209787,  0.96783191,  0.66684121],\n",
      "       [ 0.11261218,  0.51654863,  0.82631856,  0.92751431],\n",
      "       [ 0.62589312,  0.95577234,  0.44837642,  0.72862983],\n",
      "       [ 0.7295506 , -0.01019237,  0.81780314,  0.85530108]], dtype=float32)]\n",
      "Layer1_biases: [array([ 0.72157198,  0.21901333,  0.18329522,  0.73518836], dtype=float32)]\n",
      "Output_Layer_Weights: [array([[ 0.92760313,  0.49846038,  0.77919585, -0.00339385],\n",
      "       [ 0.49713448,  0.40421763,  0.91601098,  0.45360202],\n",
      "       [ 0.42165235,  0.36675367,  0.54192996,  0.4297418 ],\n",
      "       [ 0.21148856,  0.66167408,  0.18176165,  0.5562368 ]], dtype=float32)]\n",
      "Output_Layer_biases: [array([ 0.99695516,  0.61271167,  0.9265157 ,  0.88639641], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#Recover model and print weights and biases\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, model_dir+\"RC_classifier.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    print(\"Training loss:\",sess.run([soft_cross_entropy],feed_dict={X:InputX1train,Y:InputY1train}))\n",
    "    print(\"Layer1_Weights:\",sess.run([W_fc1]))\n",
    "    print(\"Layer1_biases:\",sess.run([b_fc1]))\n",
    "    print(\"Output_Layer_Weights:\",sess.run([W_fO]))\n",
    "    print(\"Output_Layer_biases:\",sess.run([b_fO]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing\n",
    "R1 = input(\"Enter Filter Resistance R1 (0.5Kto 10K):\")\n",
    "C1 = input(\"Enter Filter Capacitance C1 (1e-7 to 1e-9):\")\n",
    "R2 = input(\"Enter Filter Resistance R2 (0.5K to 10K):\")\n",
    "C2 = input(\"Enter Filter Capacitance C2 (1e-7 to 1e-9):\")\n",
    "\n",
    "InputX2 = np.asarray([[R1,C1,R2,C2]],dtype=np.float32)\n",
    "InputX2_norm = (InputX2-X1_min)/(X1_max-X1_min)\n",
    "InputX1test = np.resize(InputX2_norm,(1,Xfeatures))\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk for validation.\n",
    "    saver.restore(sess,  model_dir+\"RC_classifier.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    #print(\"Final validation loss:\",sess.run([mean_square],feed_dict={X:InputX1v,Y:InputY1v}))\n",
    "    print(\"Filter Type:\",sess.run([output_layer_pred],feed_dict={X:InputX1test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recover model and re-run training session\n",
    "with tf.Session() as sess:\n",
    "    train_writer = tf.summary.FileWriter(\"summaries_dir\",sess.graph)  #For writing summaries\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, model_dir+\"RC_classifier.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    \n",
    "    print(\"Training loss:\",sess.run([soft_cross_entropy],feed_dict={X:InputX1train,Y:InputY1train}))\n",
    "    for i in range(training_epochs):\n",
    "        summary,_ = sess.run([merged,train_step],feed_dict={X:InputX1train,Y:InputY1train})\n",
    "        train_writer.add_summary(summary, i)\n",
    "        \n",
    "        if i%display_epoch ==0:\n",
    "            print(\"Iteration:\",i)\n",
    "            print(\"Training loss:\",sess.run([soft_cross_entropy],feed_dict={X:InputX1train,Y:InputY1train}))\n",
    "            print(\"Training accuracy:\",sess.run([accuracy],feed_dict={X:InputX1train,Y:InputY1train}))\n",
    "            print(\"Validation loss:\",sess.run([soft_cross_entropy],feed_dict={X:InputX1v,Y:InputY1v}))\n",
    "            print(\"Learning rate:\",sess.run([learning_rate]))   \n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(sess, model_dir+\"RC_classifier.ckpt\")\n",
    "    #/tmp/RC_filter/RC_classifier.ckpt\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    print(\"Final training loss:\",sess.run([soft_cross_entropy],feed_dict={X:InputX1train,Y:InputY1train}))\n",
    "    print(\"Final Training accuracy:\",sess.run([accuracy],feed_dict={X:InputX1train,Y:InputY1train}))\n",
    "    print(\"Final validation loss:\",sess.run([soft_cross_entropy],feed_dict={X:InputX1v,Y:InputY1v}))\n",
    "    print(\"Labels:\",sess.run([class_labels],feed_dict={Y:InputY1train}))\n",
    "    print(\"Prediction:\",sess.run([class_pred],feed_dict={X:InputX1train}))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
